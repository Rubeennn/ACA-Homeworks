import xgboost as xgb
import pandas as pd
import lime
import lime.lime_tabular

# Assuming you have trained your XGBoost model and loaded your dataset 'data' and 'target'
# Train your XGBoost model
xgb_model = xgb.XGBClassifier()
xgb_model.fit(data, target)

# Create the LIME explainer
explainer = lime.lime_tabular.LimeTabularExplainer(data, feature_names=[f'feature_{i}' for i in range(data.shape[1])],
                                                  class_names=[f'class_{i}' for i in range(len(xgb_model.classes_))],
                                                  mode='classification')

# Select a sample data point for explanation
sample_idx = 0
sample_data = data[sample_idx]

# Explain the prediction for the sample data point using LIME
explanations = []
for class_idx in range(len(xgb_model.classes_)):
    exp = explainer.explain_instance(sample_data, xgb_model.predict_proba, labels=[class_idx], num_features=5)
    explanations.append(exp.as_list(label=class_idx))

# Print the decision paths for each class
for class_idx, class_name in enumerate(xgb_model.classes_):
    print(f"{class_name}")
    for feature, value in explanations[class_idx]:
        if value > 0:
            print(f"{feature} > {value}")
        else:
            print(f"{feature} <= {-value}")
    print()
