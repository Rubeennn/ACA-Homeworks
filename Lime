import xgboost as xgb
import shap
import numpy as np

# Assuming you have trained your XGBoost model and loaded your dataset 'data' and 'target'
# Train your XGBoost model
xgb_model = xgb.XGBClassifier()
xgb_model.fit(data, target)

# Initialize the SHAP explainer with the trained XGBoost model
explainer = shap.Explainer(xgb_model)

# Calculate SHAP values for the entire dataset
shap_values = explainer.shap_values(data)

# Calculate the absolute mean SHAP values for each feature
mean_abs_shap_values = np.mean(np.abs(shap_values), axis=0)

# Sort the features based on their absolute mean SHAP values in descending order
sorted_features_idx = np.argsort(mean_abs_shap_values)[::-1]
sorted_features_names = [f'Feature_{i}' for i in sorted_features_idx]

# Extract the thresholds for each feature from the XGBoost model
thresholds = xgb_model.get_booster().trees_to_dataframe()[['Feature', 'Split']].groupby('Feature').mean()

# Textual explanation with features and thresholds sorted by importance
explanation_text = "Features and Thresholds:\n"
for feature_name in sorted_features_names:
    threshold_value = thresholds.loc[feature_name, 'Split']
    explanation_text += f"{feature_name} > {threshold_value:.2f}\n"

print(explanation_text)
