{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMq1t5Ja1XfNRd60N5fT5t0",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Rubeennn/ACA-Homeworks/blob/main/VAE_Homework.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "J3dyrFL1LOJw"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import tensorflow.keras.layers as L\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# The following code fetches you two datasets: images, usable for autoencoder training and attributes.\n",
        "# Those attributes will be required for the final part of the assignment (applying smiles), so please keep them in mind\n",
        "from lfw_dataset import fetch_lfw_dataset\n",
        "\n",
        "data, attrs = fetch_lfw_dataset()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yGYDTKeXLhLa",
        "outputId": "b34e837b-756a-42e0-a420-430250b31ba2"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "images not found, donwloading...\n",
            "extracting...\n",
            "done\n",
            "attributes not found, downloading...\n",
            "done\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = data[:10000].reshape((10000, -1))\n",
        "print(X_train.shape)\n",
        "X_val = data[10000:].reshape((-1, X_train.shape[1]))\n",
        "print(X_val.shape)\n",
        "\n",
        "image_h = data.shape[1]\n",
        "image_w = data.shape[2]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fWGMsBJMpj1A",
        "outputId": "c624278e-b0af-44fe-9ca3-2b4ff57ac60e"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10000, 6075)\n",
            "(3143, 6075)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = np.float32(X_train)\n",
        "X_train = X_train/255\n",
        "X_val = np.float32(X_val)\n",
        "X_val = X_val/255"
      ],
      "metadata": {
        "id": "F0nL5o2Opa39"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_gallery(images, h, w, n_row=3, n_col=6):\n",
        "    \"\"\"Helper function to plot a gallery of portraits\"\"\"\n",
        "    plt.figure(figsize=(1.5 * n_col, 1.7 * n_row))\n",
        "    plt.subplots_adjust(bottom=0, left=.01, right=.99, top=.90, hspace=.35)\n",
        "    for i in range(n_row * n_col):\n",
        "        plt.subplot(n_row, n_col, i + 1)\n",
        "        plt.imshow(images[i].reshape((h, w, 3)), cmap=plt.cm.gray, vmin=-1, vmax=1, interpolation='nearest')\n",
        "        plt.xticks(())\n",
        "        plt.yticks(())"
      ],
      "metadata": {
        "id": "ttYDv4DtpuLm"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DisplayCallback(tf.keras.callbacks.Callback):\n",
        "    def __init__(self, model, rate):\n",
        "        super(DisplayCallback, self).__init__()\n",
        "        self.model = model\n",
        "        self.rate = rate\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        model = self.model\n",
        "        if epoch % self.rate == 0:\n",
        "#             print(model.weights[1], model.weights[-1])\n",
        "            print(model.weights[1][0])\n",
        "            idx = np.random.choice(X_train.shape[0])\n",
        "            plt.subplot(221)\n",
        "            plt.imshow(X_train[idx].reshape(\n",
        "                (image_h, image_w, 3)\n",
        "            ))\n",
        "            plt.subplot(222)\n",
        "            plt.imshow(tf.reshape(\n",
        "                model(X_train[tf.newaxis, idx]), (image_h, image_w, 3)\n",
        "            ))\n",
        "            idx = np.random.choice(X_val.shape[0])\n",
        "            plt.subplot(223)\n",
        "            plt.imshow(X_val[idx].reshape(\n",
        "                (image_h, image_w, 3)\n",
        "            ))\n",
        "            plt.subplot(224)\n",
        "            plt.imshow(tf.reshape(\n",
        "                model(X_val[tf.newaxis, idx]), (image_h, image_w, 3)\n",
        "            ))\n",
        "            plt.show()"
      ],
      "metadata": {
        "id": "R2x0vnjjpuIe"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow import keras"
      ],
      "metadata": {
        "id": "87VMT9fJpt-y"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Sample(keras.layers.Layer):\n",
        "    def __init__(self):\n",
        "        super(Sample, self).__init__()\n",
        "\n",
        "    def call(self, inputs):\n",
        "        mean, std = inputs\n",
        "\n",
        "        epsilon = tf.random.normal(shape=(256,))\n",
        "        sample = tf.multiply(0.5 * tf.exp(std), epsilon)\n",
        "        z = tf.add(mean, sample)\n",
        "\n",
        "        return z, mean, std\n",
        "\n",
        "inputs = tf.keras.Input(shape=(6075,))\n",
        "e1 = L.Dense(units=1024, activation='relu', kernel_initializer='glorot_uniform')(inputs)\n",
        "e2 = L.Dense(units=512, activation='relu', kernel_initializer='glorot_uniform')(e1)\n",
        "\n",
        "mean = L.Dense(units=256, kernel_initializer='glorot_uniform', name='mean')(e2)\n",
        "std = L.Dense(units=256, activation='relu', kernel_initializer='glorot_uniform', name='std')(e2)\n",
        "sample = Sample()\n",
        "z = sample([mean, std])\n",
        "lattent = L.Dense(units=128, activation='relu', kernel_initializer='glorot_uniform')(z[0])\n",
        "d1 = L.Dense(units=256, activation='relu', kernel_initializer='glorot_uniform')(lattent)\n",
        "d2 = L.Dense(units=512, activation='relu', kernel_initializer='glorot_uniform')(d1)\n",
        "d3 = L.Dense(units=1024, activation='relu', kernel_initializer='glorot_uniform')(d2)\n",
        "\n",
        "encoded = L.Dense(units=6075, activation='sigmoid')(d3)\n",
        "\n",
        "encoder = tf.keras.Model(inputs, z)\n",
        "decoder = tf.keras.Model(z[0], encoded)\n"
      ],
      "metadata": {
        "id": "PDzR2yEVptxy"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encoder.summary(), decoder.summary()"
      ],
      "metadata": {
        "id": "jMAwBpNtptsG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class VAE(tf.keras.Model):\n",
        "    def __init__(self, encoder, decoder, **kwargs):\n",
        "        super(VAE, self).__init__(**kwargs)\n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "        self.optimizer = tf.keras.optimizers.Adam()\n",
        "\n",
        "    @tf.function\n",
        "    def KL_divergence(self, mu, sigma):\n",
        "      return tf.reduce_sum(tf.multiply(-0.5, (1 + tf.math.log(sigma) - tf.square(mu) - tf.square(sigma))))\n",
        "\n",
        "    @tf.function\n",
        "    def log_likelihood(self, x, z):\n",
        "      return tf.reduce_sum((1 / x.shape[1]) * (x - z)**2)\n",
        "\n",
        "    def train_step(self, data):\n",
        "\n",
        "      with tf.GradientTape() as tape:\n",
        "\n",
        "        encoder_out = self.encoder(data)\n",
        "        decoder_out = self.decoder(encoder_out[0])\n",
        "\n",
        "        loss = self.KL_divergence(encoder_out[1], encoder_out[2]) + self.log_likelihood(data, decoder_out)\n",
        "\n",
        "      gradients = tape.gradient(loss, self.trainable_variables)\n",
        "\n",
        "      self.optimizer.apply_gradients(zip(gradients, self.trainable_variables))\n",
        "\n",
        "      return loss\n",
        "\n",
        "\n",
        "    def call(self, inputs):\n",
        "        mean, std = self.encoder(inputs)\n",
        "\n",
        "        epsilon = tf.random.normal(shape=(256,))\n",
        "        sample = tf.multiply(0.5 * tf.exp(std), epsilon)\n",
        "        z = tf.add(mean, sample)\n",
        "\n",
        "        rec_x = self.decoder(z)\n",
        "\n",
        "        return rec_x"
      ],
      "metadata": {
        "id": "UqkgKCHwptgV"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# inputs = tf.keras.Input(shape=(6075,))\n",
        "# e1 = L.Dense(units=1024, activation='relu', kernel_initializer='glorot_uniform')(inputs)\n",
        "# e2 = L.Dense(units=512, activation='relu', kernel_initializer='glorot_uniform')(e1)\n",
        "\n",
        "# mean = L.Dense(units=256, kernel_initializer='glorot_uniform', name='mean')(e2)\n",
        "# std = L.Dense(units=256, activation='relu', kernel_initializer='glorot_uniform', name='std')(e2)\n",
        "# sample = Sample()\n",
        "# z = sample([mean, std])\n",
        "# lattent = L.Dense(units=128, activation='relu', kernel_initializer='glorot_uniform')(z[0])\n",
        "# d1 = L.Dense(units=256, activation='relu', kernel_initializer='glorot_uniform')(lattent)\n",
        "# d2 = L.Dense(units=512, activation='relu', kernel_initializer='glorot_uniform')(d1)\n",
        "# d3 = L.Dense(units=1024, activation='relu', kernel_initializer='glorot_uniform')(d2)\n",
        "\n",
        "# encoded = L.Dense(units=6075, activation='sigmoid')(d3)\n",
        "\n",
        "# encoder = tf.keras.Model(inputs, z)\n",
        "# decoder = tf.keras.Model(z[0], encoded)\n"
      ],
      "metadata": {
        "id": "Eza-2XxNEzc2"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# class VAE(tf.keras.Model):\n",
        "#     def __init__(self, encoder, decoder, **kwargs):\n",
        "#         super(VAE, self).__init__(**kwargs)\n",
        "#         self.encoder = encoder\n",
        "#         self.decoder = decoder\n",
        "#         self.optimizer = tf.keras.optimizers.Adam()\n",
        "\n",
        "#     @tf.function\n",
        "#     def KL_divergence(self, mu, sigma):\n",
        "#       return tf.reduce_sum(tf.multiply(-0.5, (1 + tf.math.log(sigma) - tf.square(mu) - tf.square(sigma))))\n",
        "\n",
        "#     @tf.function\n",
        "#     def log_likelihood(self, x, z):\n",
        "#       return tf.reduce_sum((1 / x.shape[1]) * (x - z)**2)\n",
        "\n",
        "#     def train_step(self, data):\n",
        "\n",
        "#       with tf.GradientTape() as tape:\n",
        "\n",
        "#         reconstructed_x = self.call(data)\n",
        "#         mean, std = self.encoder(data)\n",
        "#         kl_loss = self.KL_divergence(mean, std)\n",
        "#         loss = self.KL_divergence(mean, std) + self.log_likelihood(data, decoder_out)\n",
        "\n",
        "#       gradients = tape.gradient(loss, self.trainable_variables)\n",
        "\n",
        "#       self.optimizer.apply_gradients(zip(gradients, self.trainable_variables))\n",
        "\n",
        "#       return loss\n",
        "\n",
        "\n",
        "#     def call(self, inputs):\n",
        "#         mean, std = self.encoder(inputs)\n",
        "\n",
        "#         epsilon = tf.random.normal(shape=(256,))\n",
        "#         sample = tf.multiply(0.5 * tf.exp(std), epsilon)\n",
        "#         z = tf.add(mean, sample)\n",
        "\n",
        "#         rec_x = self.decoder(z)\n",
        "\n",
        "#         return rec_x"
      ],
      "metadata": {
        "id": "3rzOMzGHEBB9"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a = VAE(encoder, decoder)"
      ],
      "metadata": {
        "id": "gl1X91KMqM-M"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_tensor = tf.convert_to_tensor(X_train, dtype=tf.float32)\n"
      ],
      "metadata": {
        "id": "_7tMzwmY-Apd"
      },
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(10):\n",
        "  loss = a.train_step(X_train)\n",
        "  print(loss)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zzdhw1uqqM4S",
        "outputId": "524c5683-4393-43c1-d7c2-94e743a0440c"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:5 out of the last 5 calls to <function _BaseOptimizer._update_step_xla at 0x7f6e14099ea0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:6 out of the last 6 calls to <function _BaseOptimizer._update_step_xla at 0x7f6e14099ea0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(inf, shape=(), dtype=float32)\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "callback = DisplayCallback(a, 2)\n",
        "a.compile(optimizer=tf.keras.optimizers.Adam())\n"
      ],
      "metadata": {
        "id": "Rpl2KvV8_4KQ"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = a.fit(\n",
        "\n",
        "                X_train,\n",
        "                batch_size=64,\n",
        "                callbacks=[callback],\n",
        "                validation_data=(X_val, X_val),\n",
        "                epochs=1)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 384
        },
        "id": "XP_wZv0fqMvx",
        "outputId": "c7c31142-7b77-4374-f74b-438ca450962b"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-22-ad38795c9156>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m history = a.fit(\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m                 \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                 \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                 \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcallback\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36m_batch_update_progbar\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m   1168\u001b[0m             \u001b[0;31m# Only block async when verbose = 1.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1169\u001b[0m             \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msync_to_numpy_or_python_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1170\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprogbar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinalize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1171\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1172\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_finalize_progbar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcounter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'float' object has no attribute 'items'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a = tf.constant([5,6,5])\n",
        "a * 0.5"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 332
        },
        "id": "rzYy0rDEqMmD",
        "outputId": "c0402cd0-3f28-423f-da14-71e7f55f5a5d"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-55-2996d4744070>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0ma\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    154\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/ops/gen_math_ops.py\u001b[0m in \u001b[0;36mmul\u001b[0;34m(x, y, name)\u001b[0m\n\u001b[1;32m   6574\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mtld\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_eager\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6575\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6576\u001b[0;31m       _result = pywrap_tfe.TFE_Py_FastPathExecute(\n\u001b[0m\u001b[1;32m   6577\u001b[0m         _ctx, \"Mul\", name, x, y)\n\u001b[1;32m   6578\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: Cannot convert 0.5 to EagerTensor of dtype int32"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_OIuEtwqehjG"
      },
      "source": [
        "And the last, but not least! Place in the code where the most of the formulaes goes to - optimization objective. The objective for VAE has it's own name - variational lowerbound. And as for any lowerbound our intention is to maximize it. Here it is (for one sample $z$ per input $x$):\n",
        "\n",
        "$$\\mathcal{L} = -D_{KL}(q_{\\phi}(z|x)||p_{\\theta}(z)) + \\log p_{\\theta}(x|z)$$\n",
        "\n",
        "Your next task is to implement two functions that compute KL-divergence and the second term - log-likelihood of an output. Here is some necessary math for your convenience:\n",
        "\n",
        "$$D_{KL} = -\\frac{1}{2}\\sum_{i=1}^{dimZ}(1+log(\\sigma_i^2)-\\mu_i^2-\\sigma_i^2)$$\n",
        "$$\\log p_{\\theta}(x|z) = \\sum_{i=1}^{dimX}\\log p_{\\theta}(x_i|z)=\\sum_{i=1}^{dimX} \\log \\Big( \\frac{1}{\\sigma_i\\sqrt{2\\pi}}e^{-\\frac{(\\mu_I-x)^2}{2\\sigma_i^2}} \\Big)=...$$"
      ]
    }
  ]
}